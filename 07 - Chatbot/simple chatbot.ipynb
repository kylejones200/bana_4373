{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74df4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0f2b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jnesnky/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jnesnky/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "import random \n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f97b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "  return tokens\n",
    "\n",
    "def bag_of_words(text, vocab): \n",
    "  tokens = clean_text(text)\n",
    "  bow = [0] * len(vocab)\n",
    "  for w in tokens: \n",
    "    for idx, word in enumerate(vocab):\n",
    "      if word == w: \n",
    "        bow[idx] = 1\n",
    "  return np.array(bow)\n",
    "\n",
    "def pred_class(text, vocab, labels): \n",
    "  bow = bag_of_words(text, vocab)\n",
    "  result = model.predict(np.array([bow]))[0]\n",
    "  thresh = 0.2\n",
    "  y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
    "\n",
    "  y_pred.sort(key=lambda x: x[1], reverse=True)\n",
    "  return_list = []\n",
    "  for r in y_pred:\n",
    "    return_list.append(labels[r[0]])\n",
    "  return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json): \n",
    "  tag = intents_list[0]\n",
    "  list_of_intents = intents_json[\"intents\"]\n",
    "  for i in list_of_intents: \n",
    "    if i[\"tag\"] == tag:\n",
    "      result = random.choice(i[\"responses\"])\n",
    "      break\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3dfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used a dictionary to represent an intents JSON file\n",
    "data = {\"intents\": [\n",
    "             {\"tag\": \"greeting\",\n",
    "              \"patterns\": [\"Hello\", \"How are you\", \"Hi there\", \"Hi\", \"Whats up\"],\n",
    "              \"responses\": [\"Howdy Partner!\", \"Hello\", \"How are you doing?\", \"Greetings!\", \"How do you do?\"],\n",
    "             },\n",
    "             {\"tag\": \"age\",\n",
    "              \"patterns\": [\"how old are you\", \"when is your birthday\", \"when was you born\"],\n",
    "              \"responses\": [\"I am 30 years old\", \"I was born in 1991\", \"My birthday is July 3rd and I was born in 1991\", \"03/07/1991\"]\n",
    "             },\n",
    "             {\"tag\": \"date\",\n",
    "              \"patterns\": [\"what are you doing this weekend\",\n",
    "\"do you want to hang out some time?\", \"what are your plans for this week\"],\n",
    "              \"responses\": [\"I am available all week\", \"I don't have any plans\", \"I am not busy\"]\n",
    "             },\n",
    "             {\"tag\": \"name\",\n",
    "              \"patterns\": [\"what's your name\", \"what are you called\", \"who are you\"],\n",
    "              \"responses\": [\"My name is Kylebot\", \"I'm Kylebot\", \"Kylebot\"]\n",
    "             },\n",
    "             {\"tag\": \"goodbye\",\n",
    "              \"patterns\": [ \"bye\", \"g2g\", \"see ya\", \"adios\", \"cya\"],\n",
    "              \"responses\": [\"It was nice speaking to you\", \"See you later\", \"Speak soon!\"]\n",
    "             }\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f28a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing lemmatizer to get stem of words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Each list to create\n",
    "words = []\n",
    "classes = []\n",
    "doc_X = []\n",
    "doc_y = []\n",
    "# Loop through all the intents\n",
    "# tokenize each pattern and append tokens to words, the patterns and\n",
    "# the associated tag to their associated list\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens = nltk.word_tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        doc_X.append(pattern)\n",
    "        doc_y.append(intent[\"tag\"])\n",
    "    \n",
    "    # add the tag to the classes if it's not there already \n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "# lemmatize all the words in the vocab and convert them to lowercase\n",
    "# if the words don't appear in punctuation\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
    "# sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplicates occur\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c530ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for training data\n",
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "# creating the bag of words model\n",
    "for idx, doc in enumerate(doc_X):\n",
    "    bow = []\n",
    "    text = lemmatizer.lemmatize(doc.lower())\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    # mark the index of class that the current pattern is associated\n",
    "    # to\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(doc_y[idx])] = 1\n",
    "    # add the one hot encoded BoW and associated classes to training \n",
    "    training.append([bow, output_row])\n",
    "# shuffle the data and convert it to an array\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "# split the features and target labels\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_y = np.array(list(training[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3d1af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               5120      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 13,701\n",
      "Trainable params: 13,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 1.6465 - accuracy: 0.0526\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5898 - accuracy: 0.2632\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4625 - accuracy: 0.5263\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3141 - accuracy: 0.6842\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2962 - accuracy: 0.6316\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1644 - accuracy: 0.6316\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8971 - accuracy: 0.8947\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8225 - accuracy: 0.8947\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.8947\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8217f8c8b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining some parameters\n",
    "input_shape = (len(train_X[0]),)\n",
    "output_shape = len(train_y[0])\n",
    "epochs = 10\n",
    "# the deep learning model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(output_shape, activation = \"softmax\"))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "model.fit(x=train_X, y=train_y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13cd239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Greetings!\n",
      "how old are you?\n",
      "I am 30 years old\n",
      "what is your name?\n",
      "Hello\n",
      "what is your name?\n",
      "How are you doing?\n",
      "name?\n",
      "It was nice speaking to you\n",
      "goodbye\n",
      "See you later\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-19466bcd30c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# running the chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# running the chatbot\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    intents = pred_class(message, words, classes)\n",
    "    result = get_response(intents, data)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bea2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8219da2910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def answer_question(paragraph, question):\n",
    "    message = question\n",
    "    intents = pred_class(message, words, classes)\n",
    "    result = get_response(intents, data)\n",
    "    return result\n",
    "\n",
    "gr.Interface(fn=answer_question, inputs=[\"textbox\", \"text\"], outputs=\"text\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c636ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
